{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPG3bgxgQhL2UZ0oJkZLYMt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 문제\n","Jake 마켓은 럭키백 이벤트를 오픈하고 나서 매출이 껑충 뛰었다.   \n","고객들은 수산물과 IT를 접목한 이 상품을 매우 좋아했다.   \n","이제 각지에서 Jake 마켓에 수산물을 공급하겠다고 아우성이다.   \n","   \n","영업 팀은 매주 7개의 생선 중에서 일부를 무작위로 골라 머신러닝 모델을 학습할 수 있게 훈련 데이터를 제공하고 있다.   \n","하지만 수산물을 공급하겠다는 곳이 너무 많아 샘플을 골라내는 일이 너무 힘들다.   \n","게다가 추가되는 수산물은 아직 샘플을 가지고 있지도 않다.   \n","영업 팀은 새로운 생선이 도착하는 대로 가능한 즉시 훈련 데이터를 제공하겠다고 약속했다.   \n","하지만 어느 생선이 먼저 올지도, 모든 생선이 도착할 때까지 기다릴 수도 없다.   \n","이제 어떻게 해야 할까?"],"metadata":{"id":"4LTMvDcu3_DT"}},{"cell_type":"markdown","source":["# 점진적인 학습\n","Jake 마켓이 당면한 문제는 훈련 데이터가 한 번에 준비되는 것이 아니라 조금씩 전달된다는 것이다.   \n","도착하는 대로 생선을 판매해야 하므로 데이터가 쌓일 때까지 무작정 기다릴 수도 없다.   \n","그렇다면 기존의 훈련 데이터에 새로운 데이터를 추가하여 모델을 매일매일 다시 훈련하면 어떨까?   \n","   \n","꽤 괜찮은 아이디어이다.   \n","이렇게 하면 매일 추가되는 새로운 데이터를 활용해 모델을 훈련할 수 있다.   \n","한 가지 단점은 시간이 지날수록 데이터가 늘어나는 것이다.   \n","처음 며칠은 괜찮겠지만, 몇 달이 지나면 모델을 훈련하기 위한 서버를 늘려야 한다.   \n","확실히 이는 지속 가능한 방법은 아닌 것 같다.   \n","   \n","또 다른 방법은 새로운 데이터를 추가할 때, 이전 데이터를 버림으로써 훈련 데이터 크기를 일정하게 유지하는 것이다.   \n","이렇게 하면 데이터셋의 크기가 너무 커지지 않을 수 있다.   \n","하지만 데이터를 버릴 때 다른 데이터에 없는 중요한 생선 데이터가 포함되어 있다면 큰일이다.   \n","앞으로 모델이 그 생선을 제대로 예측하지 못할 테니까 말이다.   \n","   \n","위에서 언급한 방법은 이전에 훈련한 모델을 버리고 다시 새로운 모델을 훈련하는 방식이다.   \n","**앞서 훈련한 모델을 버리지 않고 새로운 데이터에 대해서만 조금씩 더 훈련할 수 없을까?**   \n","이렇게 할 수 있다면 훈련에 사용한 데이터를 모두 유지할 필요도 없고, 앞서 학습한 생선을 까먹을 일도 없을 것이다.   \n","   \n","이런 식의 훈련 방식을 **점진적 학습** 또는 온라인 학습이라고 부른다.   \n","대표적인 점진적 학습 알고리즘은 **확률적 경사 하강법(Stochastic Gradient Descent)**이다.   \n","물론 사이킷런에서도 확률적 경사 하강법을 위한 클래스를 제공한다."],"metadata":{"id":"dnJt6cDRXAC_"}},{"cell_type":"markdown","source":["# 확률적 경사 하강법\n","확률적 경사 하강법에서 확률적이란 말은 `무작위하게` 혹은 `랜덤하게`의 기술적인 표현이다.   \n","그다음 `경사`는 `기울기`를 말한다.   \n","`하강법`은 `내려가는 방법`이다.   \n","다시 말해 경사 하강법은 경사를 따라 내려가는 방법을 말한다.   \n","   \n","예를 들어 산에서 내려온다고 생각해 본다.   \n","집으로 돌아가려면 등산로 입구까지 내려가야 한다.   \n","만약 어떤 산길도 장애물에 구애받지 않고 척척 내려갈 수 있다면 가장 빠른 길을 선택하는 것이 좋다.   \n","가장 빠른 길은 경사가 가장 가파른 길이다.   \n","   \n","위의 예시는 조금 과장되었지만, 실제로 산에서 내려올 때는 천천히 조금씩 내려와야 한다.   \n","장애물이란 변수가 많기 때문이다.   \n","경사 하강법도 마찬가지이다.   \n","가장 가파른 길을 찾아 내려오지만 조금씩 내려오는 것이 중요하다.   \n","이렇게 내려오는 과정이 바로 경사 하강법 모델을 훈련하는 것이다.   \n","   \n","그럼 이제 **확률적**이란 말을 이해할 차례이다.   \n","경사 하강법으로 내려올 때 가장 가파른 길을 찾는 방법은 무엇일까?   \n","훈련 세트를 사용해 모델을 훈련하기 때문에 경사 하강법도 당연히 훈련 세트를 사용하여 가장 가파른 길을 찾을 것이다.   \n","그런데 전체 샘플을 사용하지 않고 딱 하나의 샘플을 훈련 세트에서 랜덤하게 골라 가장 가파른 길을 찾는다.   \n","이처럼 훈련 세트에서 랜덤하게 하나의 샘플을 고르는 것이 바로 **확률적 경사 하강법**이다.   \n","   \n","조금 더 자세히 설명하면 다음과 같다.   \n","확률적 경사 하강법은 훈련 세트에서 랜덤하게 하나의 샘플을 선택하여 가파른 경사를 조금 내려간다.   \n","그다음 훈련 세트에서 랜덤하게 또 다른 샘플을 하나 선택하여 경사를 조금 내려간다.   \n","이런 식으로 전체 샘플을 모두 사용할 때까지 계속한다.   \n","   \n","이제 모든 샘플을 다 사용했다.   \n","그래도 산을 다 내려오지 못했으면 어떻게 할까?   \n","간단하다.   \n","다시 처음부터 시작하는 것이다.   \n","훈련 세트에 모든 샘플을 다시 채워 넣는다.   \n","그다음 다시 랜덤하게 하나의 샘플을 선택해 이어서 경사를 내려간다.   \n","이렇게 만족할만한 위치에 도달할 때까지 계속 내려가면 된다.   \n","확률적 경사 하강법에서 훈련 세트를 한 번 모두 사용하는 과정을 **에포크(epoch)**라고 부른다.   \n","일반적으로 경사 하강법은 수십, 수백 번 이상 에포크를 수행한다.   \n","   \n","무작위로 샘플을 선택해 산에서 내려간다면 무책임해 보일 수 있다.   \n","그래서 아주 조금씩 내려가야 한다.   \n","그렇지 않으면 돌이킬 수 없는 길로 들어설지 모른다.   \n","하지만 걱정하는 것과는 달리 확률적 경사 하강법은 꽤 잘 동작한다.   \n","만약 그래도 걱정이 된다면 1개씩 말고 무작위로 몇 개의 샘플을 선택해서 경사를 따라 내려가면 어떨까?   \n","가능하다.   \n","이렇게 여러 개의 샘플을 사용해 경사 하강법을 수행하는 방식을 **미니배치 경사 하강법(minibatch gradient descent)**이라고 한다.   \n","실전에서 아주 많이 사용한다.   \n","   \n","극단적으로 한 번 경사로를 따라 이동하기 위해 전체 샘플을 사용할 수도 있다.   \n","이를 **배치 경사 하강법(batch gradient descent)**이라고 부른다.   \n","사실 전체 데이터를 사용하기 때문에 가장 안정적인 방법이 될 수 있다.   \n","하지만 전체 데이터를 사용하면 그만큼 컴퓨터 자원을 많이 사용하게 된다.   \n","어떤 경우는 데이터가 너무너무 많아 한 번에 전체 데이터를 모두 읽을 수 없을지도 모른다.\n","\n","<img width=\"800\" alt=\"epoch\" src=\"https://github.com/kyomin/machineLearning-deepLearning/assets/46395776/33d1db51-4edc-4634-b4e6-a031d52c3646\">\n","\n","위의 그림을 보면 조금 이해가 갈 것이다.   \n","확률적 경사 하강법은 훈련 세트를 사용해 산 아래에 있는 최적의 장소로 조금씩 이동하는 알고리즘이다.   \n","이 때문에 훈련 데이터가 모두 준비되어 있지 않고 매일매일 업데이트되어도 학습을 계속 이어나갈 수 있다.   \n","즉 다시 산꼭대기에서부터 시작할 필요가 없는 것이다.   \n","   \n","그런데 어디서 내려가야 하는 것일까?   \n","다시 말해 가장 빠른 길을 찾아 내려가려고 하는 이 산은 도대체 무엇일까?   \n","이 산이 바로 **손실 함수**라 부르는 것이다."],"metadata":{"id":"t12-DU0pZFdC"}},{"cell_type":"markdown","source":["### 확률적 경사 하강법과 신경망 알고리즘\n","확률적 경사 하강법을 꼭 사용하는 알고리즘이 있다.   \n","바로 신경망 알고리즘이다.   \n","신경망은 일반적으로 많은 데이터를 사용하기 때문에 한 번에 모든 데이터를 사용하기 어렵다.   \n","또 모델이 매우 복잡하기 때문에 수학적인 방법으로 해답을 얻기 어렵다.   \n","신경망 모델이 **확률적 경사 하강법(1개씩 꺼내기)**이나 **미니배치 경사 하강법(여러 개씩 꺼내기)**을 사용한다는 점을 기억한다."],"metadata":{"id":"6S-hFcr0WbBp"}},{"cell_type":"markdown","source":["# 손실 함수\n","**손실 함수(loss function)**는 어떤 문제에서 머신러닝 알고리즘이 얼마나 엉터리인지를 측정하는 기준이다.   \n","그렇다면 손실 함수의 값이 작을수록 좋을 것이다.   \n","하지만 어떤 값이 최솟값인지는 알지 못한다.   \n","가능한 많이 찾아보고 만족할만한 수준이라면 산을 다 내려왔다고 인정해야 한다.   \n","이 값을 찾아서 조금씩 이동하려면 확률적 경사 하강법이 잘 맞을 것이다.   \n","   \n","다행히 우리가 다루는 많은 문제에 필요한 손실 함수는 이미 정의되어 있다.   \n","그럼 생선을 분류하기 위해서는 어떤 손실 함수를 사용하는지 알아본다.   \n","   \n","분류에서 손실은 아주 확실하다.   \n","정답을 못 맞히는 것이다.   \n","이해를 돕기 위해 도미와 빙어를 구분하는 이진 분류 문제를 예로 들어본다.   \n","도미는 양성 클래스(1), 빙어는 음성 클래스(0)라고 가정해 본다.   \n","다음 표와 같은 예측과 정답이 있다고 해보자.\n","\n","|예측| |정답(타깃)|\n","|:---:|:---:|:---:|\n","|1|=|0|\n","|0|≠|1|\n","|0|=|0|\n","|1|≠|0|\n","\n","정확도는 얼마일까?   \n","4개의 예측 중에 2개만 맞았으므로 정확도는 1/2=0.5이다.   \n","정확도를 손실 함수로 사용할 수 있을까?   \n","예를 들어 정확도에 음수를 취하면 -1.0이 가장 낮고 -0.0이 가장 높다.   \n","손실 함수로 괜찮아 보인다.   \n","   \n","하지만 정확도에는 치명적인 단점이 있다.   \n","예를 들어 위의 표와 같이 4개의 샘플만 있다면 가능한 정확도는 **0, 0.25, 0.5, 0.75, 1 다섯 가지**뿐이다.   \n","앞에서 경사 하강법을 사용할 때 아주 조금씩 내려온다고 했었다.   \n","정확도가 이렇게 듬성듬성하다면 경사 하강법을 이용해 조금씩 움직일 수 없다.   \n","산의 경사면은 확실히 연속적이어야 한다.   \n","**기술적으로 말하면 손실 함수는 미분 가능해야 한다.**   \n","   \n","그럼 어떻게 연속적인 손실 함수를 만들 수 있을까?   \n","앞서 **로지스틱 회귀**에서 로지스틱 회귀 모델이 확률을 출력한 것을 기억한다.   \n","예측은 0 또는 1이지만, 확률은 0 ~ 1 사이의 어떤 값도 될 수 있다.   \n","즉 연속적이다.   \n","가령 위의 샘플 4개의 예측 확률을 각각 0.9, 0.3, 0.2, 0.8이라고 가정해 본다.   \n","첫 번째 샘플부터 하나씩 어떻게 손실 함수를 만들 수 있는지 살펴본다."],"metadata":{"id":"B06rlpRtXPZl"}},{"cell_type":"markdown","source":["# 로지스틱 손실 함수\n","첫 번째 샘플의 예측은 0.9이므로 양성 클래스의 타깃인 1과 곱한 다음 음수로 바꿀 수 있다.   \n","이 경우 예측이 1에 가까울수록 좋은 모델이다.   \n","예측이 1에 가까울수록 예측과 타깃의 곱의 음수는 점점 작아진다.   \n","따라서 이 값을 손실 함수로 사용해도 괜찮아 보인다.\n","\n","|예측| |정답(타깃)| | |\n","|:---:|:---:|:---:|:---:|:---:|\n","|0.9|X|1|→|-0.9|\n","\n","두 번째 샘플의 예측은 0.3이다.   \n","타깃이 양성 클래스(1)인데 거리가 멀다.   \n","위에서와 마찬가지로 예측과 타깃을 곱해 음수로 바꿔 본다.   \n","이 값은 -0.3이 되기 때문에 확실히 첫 번째 샘플보다 높은 손실이 된다.\n","\n","|예측| |정답(타깃)| | |\n","|:---:|:---:|:---:|:---:|:---:|\n","|0.9|X|1|→|-0.9|\n","|0.3|X|1|→|-0.3|\n","\n","세 번째 샘플을 본다.   \n","이 샘플의 타깃은 음성 클래스라 0이다.   \n","이 값을 예측 확률인 0.2와 그대로 곱해서는 곤란하다.   \n","무조건 0이 될테니 말이다.   \n","한 가지 방법은 타깃을 마치 양성 클래스처럼 바꾸어 1로 만드는 것이다.   \n","대신 예측값도 양성 클래스에 대한 예측으로 바꾼다.   \n","즉 1 - 0.2 = 0.8로 사용한다.   \n","그다음 곱하고 음수로 바꾸는 것은 위와 동일하다.\n","\n","| | |예측| |정답(타깃)| | |\n","|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n","| | |0.9|X|1|→|-0.9|\n","| | |0.3|X|1|→|-0.3|\n","|0.2|→|0.8|X|1|→|-0.8|\n","\n","세 번째 샘플은 음성 클래스인 타깃을 맞추었으므로 손실이 낮아야 한다.   \n","-0.8은 꽤 낮은 손실이다.   \n","이제 네 번째 샘플을 본다.   \n","네 번째 샘플도 타깃은 음성 클래스이다.   \n","하지만 정답을 맞히지 못했다.   \n","타깃을 1로 바꾸고 예측 확률을 1에서 뺀 다음 곱해서 음수로 바꿔 본다.\n","\n","| | |예측| |정답(타깃)| | |\n","|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n","| | |0.9|X|1|→|-0.9|\n","| | |0.3|X|1|→|-0.3|\n","|0.2|→|0.8|X|1|→|-0.8|\n","|0.8|→|0.2|X|1|→|-0.2|\n","\n","네 번째 샘플의 손실이 높다.   \n","예측 확률을 사용해 이런 방식으로 계산하면 연속적인 손실 함수를 얻을 수 있을 것 같다.   \n","**여기에서 예측 확률에 로그 함수를 적용하면 더 좋다.**   \n","**예측 확률의 범위는 0 ~ 1 사이인데, 로그 함수는 이 사이에서 음수가 되므로 최종 손실 값은 양수가 된다.**   \n","손실이 양수가 되면 이해하기 더 쉽다.   \n","또 로그 함수는 0에 가까울수록 아주 큰 음수가 되기 때문에 손실을 아주 크게 만들어 모델에 큰 영향을 미칠 수 있다.\n","\n","![log_graph](https://github.com/kyomin/machineLearning-deepLearning/assets/46395776/ceb0bd78-40e2-43af-8e9c-9f4abfa88501)\n","\n","- 타깃 = 1일 때 => -log(예측 확률)\n","- 타깃 = 0일 때 => -log(1 - 예측 확률)\n","\n","정리하면 위와 같다.   \n","양성 클래스(타깃 = 1)일 때, 손실은 -log(예측 확률)로 계산한다.   \n","확률이 1에서 멀어질수록 손실은 아주 큰 양수가 된다.   \n","음성 클래스(타깃 = 0)일 때, 손실은 -log(1 - 예측 확률)로 계산한다.   \n","이 예측 확률이 0에서 멀어질수록 손실은 아주 큰 양수가 된다.   \n","   \n","위와 같이 좋은 손실 함수를 정의하였다.   \n","이 손실 함수를 **로지스틱 손실 함수(logistic loss function)**라고 부른다.   \n","또는 **이진 크로스엔트로피 손실 함수(binary cross-entropy loss function)**라고도 부른다.   \n","   \n","여기에서는 이진 분류를 예로 들어 설명했지만, 다중 분류도 매우 비슷한 손실 함수를 사용한다.   \n","다중 분류에서 사용하는 손실 함수를 **크로스엔트로피 손실 함수(cross-entropy loss function)**라고 부른다.   \n","   \n","앞서 설명했지만 사실 손실 함수를 우리가 직접 만드는 일은 거의 없다.   \n","이미 문제에 잘 맞는 손실 함수가 개발되어 있기 때문이다.   \n","이진 분류는 로지스틱 손실 함수를 사용하고 다중 분류는 크로스엔트로피 손실 함수를 사용한다.   \n","   \n","손실 함수를 직접 계산하는 일 또한 드물다.   \n","머신러닝 라이브러리가 처리해 주니까 걱정할 필요가 없다.   \n","하지만 손실 함수가 무엇인지, 왜 정의를 해야 하는지 이해하는 것이 중요하다."],"metadata":{"id":"Hv0HbXf9b16U"}},{"cell_type":"markdown","source":["### 회귀에서는 어떤 손실 함수를 사용할까?\n","회귀의 손실 함수로 평균 절댓값 오차를 사용할 수 있다.   \n","타깃에서 예측을 뺀 절댓값을 모든 샘플에 평균한 값이다.   \n","또는 **평균 제곱 오차(mean squared error)**를 많이 사용한다.   \n","타잇에서 예측을 뺀 값을 제곱한 다음 모든 샘플에 평균한 값이다.   \n","확실히 이 값이 작을수록 좋은 모델이다."],"metadata":{"id":"1k3fK0dWm4nT"}},{"cell_type":"markdown","source":["# SGDClassifier\n","fish_csv_data 파일에서 판다스 데이터프레임을 만들어 본다."],"metadata":{"id":"hQ-WmMH4nN5M"}},{"cell_type":"code","source":["import pandas as pd\n","fish = pd.read_csv('https://bit.ly/fish_csv_data')"],"metadata":{"id":"56fSaeeyncK7","executionInfo":{"status":"ok","timestamp":1691841647230,"user_tz":-540,"elapsed":424,"user":{"displayName":"에휴인생","userId":"10187713187260644638"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["그다음 Species 열을 제외한 나머지 5개는 입력 데이터로 사용한다.   \n","Species 열은 타깃 데이터이다."],"metadata":{"id":"vzEN211rnt1N"}},{"cell_type":"code","source":["fish_input = fish[['Weight', 'Length', 'Diagonal', 'Height', 'Width']].to_numpy()\n","fish_target = fish['Species'].to_numpy()"],"metadata":{"id":"iqoJY_VYn6pj","executionInfo":{"status":"ok","timestamp":1691841773607,"user_tz":-540,"elapsed":588,"user":{"displayName":"에휴인생","userId":"10187713187260644638"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["사이킷런의 train_test_split() 함수를 사용해 이 데이터를 훈련 세트와 테스트 세트로 나눈다."],"metadata":{"id":"QckC4k18oSx8"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","train_input, test_input, train_target, test_target = train_test_split(\n","    fish_input, fish_target, random_state=42\n",")"],"metadata":{"id":"5r5uORvKoZdr","executionInfo":{"status":"ok","timestamp":1691841900350,"user_tz":-540,"elapsed":10,"user":{"displayName":"에휴인생","userId":"10187713187260644638"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["이제 훈련 세트와 테스트 세트의 특성을 표준화 전처리한다.   \n","꼭 훈련 세트에서 학습한 통계 값으로 테스트 세트도 변환해야 한다."],"metadata":{"id":"3UWxSE7fou1i"}},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","ss = StandardScaler()\n","ss.fit(train_input)\n","train_scaled = ss.transform(train_input)\n","test_scaled = ss.transform(test_input)"],"metadata":{"id":"AdrrEh8ko3fy","executionInfo":{"status":"ok","timestamp":1691842015276,"user_tz":-540,"elapsed":6,"user":{"displayName":"에휴인생","userId":"10187713187260644638"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["특성값의 스케일을 맞춘 train_scaled와 test_scaled 두 넘파이 배열을 준비했다.   \n","여기까지는 이전과 동일하다.   \n","사이킷런에서 확률적 경사 하강법을 제공하는 대표적인 분류용 클래스는 `SGDClassifier`이다.   \n","sklearn.linear_model 패키지 아래에서 임포트해 본다."],"metadata":{"id":"oB_LCkdjpuCE"}},{"cell_type":"code","source":["from sklearn.linear_model import SGDClassifier"],"metadata":{"id":"xlednWP8qAcv","executionInfo":{"status":"ok","timestamp":1691842270129,"user_tz":-540,"elapsed":425,"user":{"displayName":"에휴인생","userId":"10187713187260644638"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["SGDClassifier의 객체를 만들 때 2개의 매개변수를 지정한다.   \n","loss는 손실 함수의 종류를 지정한다.   \n","여기에서는 loss='log'로 지정하여 로지스틱 손실 함수를 지정했다.   \n","max_iter는 수행할 에포크 횟수를 지정한다.   \n","10으로 지정하여 전체 훈련 세트를 10회 반복한다.   \n","그다음 훈련 세트와 테스트 세트에서 정확도 점수를 출력한다."],"metadata":{"id":"erbf0RoSqKHh"}},{"cell_type":"code","source":["sc = SGDClassifier(loss='log_loss', max_iter=10, random_state=42)\n","sc.fit(train_scaled, train_target)\n","print(sc.score(train_scaled, train_target))\n","print(sc.score(test_scaled, test_target))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FRpXCWx8qlfl","executionInfo":{"status":"ok","timestamp":1691842489819,"user_tz":-540,"elapsed":410,"user":{"displayName":"에휴인생","userId":"10187713187260644638"}},"outputId":"b64dea5f-1dc5-4f9a-ea4e-c9d876ece475"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["0.773109243697479\n","0.775\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["### ConvergenceWarning 경고\n","위의 코드를 실행하면 사이킷런은 친절하게도 모델이 충분히 수렴하지 않았다는 ConvergenceWarning 경고를 보낸다.   \n","이런 경고를 보았다면 max_iter 매개변수의 값을 늘려 주는 것이 좋다.   \n","또한 오류가 아닌 경고 레벨의 로그이므로 그대로 진행해도 좋다."],"metadata":{"id":"AlAqXAvHrDL5"}},{"cell_type":"markdown","source":["출력된 훈련 세트와 테스트 세트 정확도가 낮다.   \n","아마도 지정한 반복 횟수 10번이 부족한 것으로 보인다.   \n","   \n","앞서 이야기한 것처럼 확률적 경사 하강법은 점진적 학습이 가능하다.   \n","SGDClassifier 객체를 다시 만들지 않고 훈련한 모델 sc를 추가로 더 훈련해 본다.   \n","모델을 이어서 훈련할 때는 `partial_fit()` 메서드를 사용한다.   \n","이 메서드는 fit() 메서드와 사용법이 같지만 호출할 때마다 1 에포크씩 이어서 훈련할 수 있다.   \n","partial_fit() 메서드를 호출하고 다시 훈련 세트와 테스트 세트의 점수를 확인해 본다."],"metadata":{"id":"VVD3fxderUYu"}},{"cell_type":"code","source":["sc.partial_fit(train_scaled, train_target)\n","print(sc.score(train_scaled, train_target))\n","print(sc.score(test_scaled, test_target))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r66ApWtkr19I","executionInfo":{"status":"ok","timestamp":1691842756581,"user_tz":-540,"elapsed":529,"user":{"displayName":"에휴인생","userId":"10187713187260644638"}},"outputId":"2a783a7d-fbeb-4bb8-d3e8-1454e5990bb6"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["0.8151260504201681\n","0.85\n"]}]},{"cell_type":"markdown","source":["아직 점수가 낮지만 에포크를 한 번 더 실행하니 정확도가 향상되었다.   \n","이 모델을 여러 에포크에서 더 훈련해 볼 필요가 있다.   \n","그런데 얼마나 더 훈련해야 할까?   \n","무작정 많이 반복할 수는 없고 어떤 기준이 필요할 것 같다."],"metadata":{"id":"Qs2fY2PcsCgz"}},{"cell_type":"markdown","source":["### 위의 예시는 배치 경사 하강법인가?\n","train_scaled와 train_target을 한꺼번에 모두 사용했으니 확률적 경사 하강법이 아닌 배치 경사 하강법이 아닐까?   \n","아니다.   \n","SGDClassifier 객체에 한 번에 훈련 세트 전체를 전달했지만, 이 알고리즘은 전달한 훈련 세트에서 1개씩 샘플을 꺼내어 경사 하강법 단계를 수행한다.   \n","게다가 SGDClassifier는 미니배치 경사 하강법이나 배치 하강법을 제공하지 않는다."],"metadata":{"id":"wUOGDx_7sbat"}},{"cell_type":"markdown","source":["# 에포크와 과대/과소적합\n","앞서 공부했던 과소적합과 과대적합을 기억해 본다.   \n","확률적 경사 하강법을 사용한 모델은 에포크 횟수에 따라 과소적합이나 과대적합이 될 수 있다.   \n","왜 이런 현상이 일어나는지 잠시 생각해 본다.   \n","   \n","에포크 횟수가 적으면 모델이 훈련 세트를 덜 학습한다.   \n","마치 산을 다 내려오지 못하고 훈련을 마치는 셈이다.   \n","에포크 횟수가 충분히 많으면 훈련 세트를 완전히 학습할 것이다.   \n","훈련 세트에 아주 잘 맞는 모델이 만들어진다.   \n","   \n","바꾸어 말하면 적은 에포크 횟수 동안에 훈련한 모델은 훈련 세트와 테스트 세트에 잘 맞지 않는 과소적합된 모델일 가능성이 높다.   \n","반대로 많은 에포크 횟수 동안에 훈련한 모델은 훈련 세트에 너무 잘 맞아 테스트 세트에는 오히려 점수가 나쁜 과대적합된 모델일 가능성이 높다.\n","\n","![epoch_graph](https://github.com/kyomin/machineLearning-deepLearning/assets/46395776/bcb92c87-5416-4243-8d72-bdb2c8410891)\n","\n","위의 그래프는 에포크가 진행됨에 따라 모델의 정확도를 나타낸 것이다.   \n","훈련 세트 점수는 에포크가 진행될수록 꾸준히 증가하지만, 테스트 세트 점수는 어느 순간 감소하기 시작한다.   \n","바로 이 지점이 모델이 과대적합되기 시작하는 곳이다.   \n","과대적합이 시작하기 전에 훈련을 멈추는 것을 **조기 종료(early stopping)**라고 한다.   \n","그럼 준비한 데이터셋으로 위와 같은 그래프를 만들어 본다.   \n","   \n","이 예제에서는 fit() 메서드를 사용하지 않고 partial_fit() 메서드만 사용한다.   \n","partial_fit() 메서드만 사용하려면 훈련 세트에 있는 전체 클래스의 레이블을 partial_fit() 메서드에 전달해 주어야 한다.   \n","이를 위해 np.unique() 함수로 train_target에 있는 7개 생선의 목록을 만든다.   \n","또 에포크마다 훈련 세트와 테스트 세트에 대한 점수를 기록하기 위해 2개의 리스트를 준비한다."],"metadata":{"id":"J-4Q7EgBtDKw"}},{"cell_type":"code","source":["import numpy as np\n","sc = SGDClassifier(loss='log_loss', random_state=42)\n","train_score = []\n","test_score = []\n","classes = np.unique(train_target)"],"metadata":{"id":"jYdCXhSsxUV2","executionInfo":{"status":"ok","timestamp":1691844241792,"user_tz":-540,"elapsed":10,"user":{"displayName":"에휴인생","userId":"10187713187260644638"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["300번의 에포크 동안 훈련을 반복하여 진행해 본다.   \n","반복마다 훈련 세트와 테스트 세트의 점수를 계산하여 train_score, test_score 리스트에 추가한다."],"metadata":{"id":"QjvlfC4Qxqbe"}},{"cell_type":"code","source":["for _ in range(0, 300):\n","  sc.partial_fit(train_scaled, train_target, classes=classes)\n","  train_score.append(sc.score(train_scaled, train_target))\n","  test_score.append(sc.score(test_scaled, test_target))"],"metadata":{"id":"qElslNjSx27B","executionInfo":{"status":"ok","timestamp":1691844418768,"user_tz":-540,"elapsed":2546,"user":{"displayName":"에휴인생","userId":"10187713187260644638"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["300번의 에포크 동안 기록한 훈련 세트와 테스트 세트의 점수를 그래프로 그려 본다."],"metadata":{"id":"VEo_NfKsyVh6"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","plt.plot(train_score)\n","plt.plot(test_score)\n","plt.xlabel('epoch')\n","plt.ylabel('accuracy')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":449},"id":"2DAUzQhHyZHF","executionInfo":{"status":"ok","timestamp":1691844542564,"user_tz":-540,"elapsed":644,"user":{"displayName":"에휴인생","userId":"10187713187260644638"}},"outputId":"a785e78c-8ecd-4289-fd54-c2e70be73435"},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["데이터가 작기 때문에 아주 잘 드러나지는 않지만, 백 번째 에포크 이후에는 훈련 세트와 테스트 세트의 점수가 조금씩 벌어지고 있다.   \n","또 확실히 에포크 초기에는 과소적합되어 훈련 세트와 테스트 세트의 점수가 낮다.   \n","이 모델의 경우 백 번째 에포크가 적절한 반복 횟수로 보인다.   \n","   \n","그럼 SGDClassifier의 반복 횟수를 100에 맞추고 모델을 다시 훈련해 본다.   \n","그리고 최종적으로 훈련 세트와 테스트 세트에서 점수를 출력한다."],"metadata":{"id":"7iesMtIBy0wu"}},{"cell_type":"code","source":["sc = SGDClassifier(loss='log_loss', max_iter=100, tol=None, random_state=42)\n","sc.fit(train_scaled, train_target)\n","print(sc.score(train_scaled, train_target))\n","print(sc.score(test_scaled, test_target))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j76HAwY-1871","executionInfo":{"status":"ok","timestamp":1691845462249,"user_tz":-540,"elapsed":9,"user":{"displayName":"에휴인생","userId":"10187713187260644638"}},"outputId":"43d8741a-d3c4-49b8-958d-14050c65c342"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["0.957983193277311\n","0.925\n"]}]},{"cell_type":"markdown","source":["SGDClassifier는 일정 에포크 동안 성능이 향상되지 않으면 더 훈련하지 않고 자동으로 멈춘다.   \n","tol 매개변수에서 향상될 최솟값을 지정한다.   \n","앞의 코드에서는 tol 매개변수를 None으로 지정하여 자동으로 멈추지 않고 max_iter=100 만큼 무조건 반복하도록 하였다.   \n","   \n","최종 점수가 좋은 편이다.   \n","훈련 세트와 테스트 세트에서의 정확도 점수가 비교적 높게 나왔다."],"metadata":{"id":"2IjMnhkp2SHP"}}]}