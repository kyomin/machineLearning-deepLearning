{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNWV+vShemgO0eQMmHoeMLM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 정형 데이터와 비정형 데이터\n","그동안 다루었던 데이터를 되돌아본다.   \n","지금까지 CSV 파일을 사용했었다.   \n","이런 형태의 데이터를 **정형 데이터(structured data)**라고 부른다.   \n","쉽게 말해 어떤 구조로 되어 있다는 뜻이다.   \n","이런 데이터는 CSV나 데이터베이스(Database), 혹은 엑셀(Excel)에 저장하기 쉽다.   \n","   \n","온라인 쇼핑몰에 진열된 상품과 우리가 구매한 쇼핑 정보는 모두 데이터베이스에 저장되는 정형 데이터에 속한다.   \n","사실 프로그래머가 다루는 대부분의 데이터가 정형 데이터이다.   \n","   \n","이와 반대되는 데이터를 **비정형 데이터(unstructured data)**라고 부른다.   \n","비정형 데이터는 데이터베이스나 엑셀로 표현하기 어려운 것들이다.   \n","책의 글과 같은 텍스트 데이터, 디지털 사진, 디지털 음악 등이 있다.   \n","   \n","지금까지 배운 머신러닝 알고리즘은 정형 데이터에 잘 맞는다.   \n","그중에 정형 데이터를 다루는 데 가장 뛰어난 성과를 내는 알고리즘이 **앙상블 학습(ensemble learning)**이다.   \n","이 알고리즘은 대부분 결정 트리를 기반으로 만들어져 있다.   \n","   \n","그럼 비정형 데이터는 어떤 알고리즘을 사용해야 할까?   \n","바로 딥러닝의 신경망 알고리즘이다.   \n","비정형 데이터는 규칙성을 찾기 어려워 전통적인 머신러닝 방법으로는 모델을 만들기 까다롭다.   \n","하지만 신경망 알고리즘의 놀라운 발전 덕분에 사진을 인식하고 텍스트를 이해하는 모델을 만들 수 있다."],"metadata":{"id":"3duK5cvxiKqq"}},{"cell_type":"markdown","source":["# 랜덤 포레스트\n","**랜덤 포레스트(Random Forest)**는 앙상블 학습의 대표 주자 중 하나로 안정적인 성능 덕분에 널리 사용되고 있다.   \n","앙상블 학습을 적용할 때 가장 먼저 랜덤 포레스트를 시도해 보는 것을 권한다.   \n","   \n","이름 자체로 유추할 수 있듯이 **랜덤 포레스트는 결정 트리를 랜덤하게 만들어 결정 트리(나무)의 숲을 만든다.**   \n","그리고 각 결정 트리의 예측을 사용해 최종 예측을 만든다.   \n","그럼 랜덤 포레스트가 어떻게 숲을 구성하는지 관찰해 본다.\n","\n","![랜덤 포레스트](https://github.com/kyomin/machineLearning-deepLearning/assets/46395776/c9f7ea79-6838-4805-b7f4-df25176d66fe)\n","\n","먼저 랜덤 포레스트는 각 트리를 훈련하기 위한 데이터를 랜덤하게 만드는데, 이 데이터를 만드는 방법이 독특하다.   \n","우리가 입력한 훈련 데이터에서 랜덤하게 샘플을 추출하여 훈련 데이터를 만든다.   \n","이때 한 샘플이 중복되어 추출될 수도 있다.   \n","   \n","예를 들어 1,000개 가방에서 100개씩 샘플을 뽑는다면 먼저 1개를 뽑고, 뽑았던 1개를 다시 가방에 넣는다.   \n","이런 식으로 계속해서 100개를 가방에서 뽑으면 중복된 샘플을 뽑을 수 있다.   \n","이렇게 만들어진 샘플을 **부트스트랩 샘플(bootstrap sample)**이라고 부른다.   \n","기본적으로 부트스트랩 샘플은 훈련 세트의 크기와 같게 만든다.   \n","1,000개 가방에서 중복하여 1,000개의 샘플을 뽑기 때문에 부트스트랩 샘플은 훈련 세트와 크기가 같다.\n","\n","![부트스트랩 샘플](https://github.com/kyomin/machineLearning-deepLearning/assets/46395776/378e62db-53a7-434a-829f-085bd1269c1a)\n","\n","또한 각 노드를 분할할 때, 전체 특성 중에서 일부 특성을 무작위로 고른 다음 이 중에서 최선의 분할을 찾는다.   \n","분류 모델인 `RandomForestClassifier`는 기본적으로 전체 특성 개수의 제곱근만큼의 특성을 선택한다.   \n","즉 4개의 특성이 있다면 노드마다 2개를 랜덤하게 선택하여 사용한다.   \n","다만 회귀 모델인 `RandomForestRegressor`는 전체 특성을 사용한다.\n","\n","![랜덤 포레스트 훈련 방식](https://github.com/kyomin/machineLearning-deepLearning/assets/46395776/cea480c2-c9e1-422b-bfb8-b2dd0893d161)\n","\n","사이킷런의 랜덤 포레스트는 기본적으로 100개의 결정 트리를 이런 방식으로 훈련한다.   \n","그다음 분류일 때는 각 트리의 클래스별 확률을 평균하여 가장 높은 확률을 가진 클래스를 예측으로 삼는다.   \n","회귀일 때는 단순히 각 트리의 예측을 평균한다.   \n","   \n","랜덤 포레스트는 랜덤하게 선택한 샘플과 특성을 사용하기 때문에 훈련 세트에 과대적합되는 것을 막아주고 검증 세트와 테스트 세트에서 안정적인 성능을 얻을 수 있다.   \n","종종 기본 매개변수 설정만으로도 아주 좋은 결과를 낸다.   \n","   \n","그럼 사이킷런의 `RandomForestClassifier` 클래스를 화이트 와인을 분류하는 문제에 적용해 본다.   \n","기존해 했던 것처럼 와인 데이터셋을 판다스로 불러오고 훈련 세트와 테스트 세트로 나눈다."],"metadata":{"id":"hS2hVhfXl50t"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","wine = pd.read_csv('https://bit.ly/wine_csv_data')\n","data = wine[['alcohol', 'sugar', 'pH']].to_numpy()\n","target = wine['class'].to_numpy()\n","train_input, test_input, train_target, test_target = train_test_split(\n","    data, target, test_size=0.2, random_state=42\n",")"],"metadata":{"id":"0ONx-jXfzq6H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["cross_validate() 함수를 사용해 교차 검증을 수행해 본다.   \n","RandomForestClassifier는 기본적으로 100개의 결정 트리를 사용하므로 n_jobs 매개변수를 -1로 지정하여 모든 CPU 코어를 사용하는 것이 좋다.   \n","cross_validate() 함수의 n_jobs 매개변수도 -1로 지정하여 최대한 병렬로 교차 검증을 수행한다.   \n","또 return_train_score 매개변수를 True로 지정하면(기본값은 False) 검증 점수뿐만 아니라 훈련 세트에 대한 점수도 같이 반환한다.   \n","훈련 세트와 검증 세트의 점수를 비교하면 과대적합을 파악하는 데 용이하다."],"metadata":{"id":"P25dkjhl0qcP"}},{"cell_type":"code","source":["from sklearn.model_selection import cross_validate\n","from sklearn.ensemble import RandomForestClassifier\n","rf = RandomForestClassifier(n_jobs=-1, random_state=42)\n","scores = cross_validate(\n","    rf, train_input, train_target, return_train_score=True, n_jobs=-1\n",")\n","print(np.mean(scores['train_score']), np.mean(scores['test_score']))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XvZifYjV6rM2","executionInfo":{"status":"ok","timestamp":1695806189847,"user_tz":-540,"elapsed":3607,"user":{"displayName":"에휴인생","userId":"10187713187260644638"}},"outputId":"3d8e01c6-724b-4ad7-9efa-3ebcc79a76c2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.9973541965122431 0.8905151032797809\n"]}]},{"cell_type":"markdown","source":["출력된 결과를 보면 훈련 세트에 다소 과대적합된 모습이다.   \n","   \n","랜덤 포레스트는 결정 트리의 앙상블이기 때문에 DecisionTreeClassifier가 제공하는 중요한 매개변수를 모두 제공한다.   \n","criterian, max_depth, max_features, min_samples_split, min_impurity_decrease, min_samples_leaf 등이다.   \n","또한 결정 트리의 큰 장점 중 하나인 특성 중요도를 계산한다.   \n","**랜덤 포레스트의 특성 중요도는 각 결정 트리의 특성 중요도를 취합한 것이다.**   \n","앞의 랜덤 포레스트 모델을 훈련 세트에 훈련한 후 특성 중요도를 출력해 본다."],"metadata":{"id":"gW78i2N97SWO"}},{"cell_type":"code","source":["rf.fit(train_input, train_target)\n","print(rf.feature_importances_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aQvzCqqM8UZe","executionInfo":{"status":"ok","timestamp":1695806499367,"user_tz":-540,"elapsed":2660,"user":{"displayName":"에휴인생","userId":"10187713187260644638"}},"outputId":"10100400-e27c-44d3-93ce-b17f87ec0b74"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.23167441 0.50039841 0.26792718]\n"]}]},{"cell_type":"markdown","source":["랜덤 포레스트를 사용하지 않은 결정트리만으로 만든 특성 중요도와 달라진 결과가 나온다.   \n","각각 [알코올 도수, 당도, pH]였는데, 두 번째 특성인 당도의 중요도가 감소하고 알코올 도수와 pH 특성의 중요도가 조금 상승했다.   \n","이런 이유는 랜덤 포레스트가 특성의 일부를 랜덤하게 선택하여 결정 트리를 훈련하기 때문이다.   \n","그 결과 하나의 특성에 과도하게 집중하지 않고 좀 더 많은 특성이 훈련에 기여할 기회를 얻는다.   \n","이는 과대적합을 줄이고 일반화 성능을 높이는 데 도음이 된다.   \n","   \n","RandomForestClassifier에는 재미있는 기능이 하나 더 있는데, 자체적으로 모델을 평가하는 점수를 얻을 수 있다.   \n","랜덤 포레스트는 훈련 세트에서 중복을 허용하여 부트스트랩 샘플을 만들어 결정 트리를 훈련한다고 했다.   \n","이때 부트스트랩 샘플에 포함되지 않고 남는 샘플이 있다.   \n","이런 샘플을 OOB(out of bag) 샘플이라고 한다.   \n","이 남는 샘플을 사용하여 부트스트랩 샘플로 훈련한 결정 트리를 평가할 수 있다.   \n","마치 검증 세트의 역할을 하는 것이다.   \n","   \n","이 점수를 얻으려면 RandomForestClassifier 클래스의 oob_score 매개변수를 True로 지정해야 한다(디폴트는 False).   \n","이렇게 하면 랜덤 포레스트는 각 결정 트리의 OOB 점수를 평균하여 출력한다.   \n","그럼 OOB 점수를 출력해 본다."],"metadata":{"id":"j95MrItQ8cbQ"}},{"cell_type":"code","source":["rf = RandomForestClassifier(oob_score=True, n_jobs=-1, random_state=42)\n","rf.fit(train_input, train_target)\n","print(rf.oob_score_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cmkjLxuC91BL","executionInfo":{"status":"ok","timestamp":1695807225622,"user_tz":-540,"elapsed":1475,"user":{"displayName":"에휴인생","userId":"10187713187260644638"}},"outputId":"3f88e924-009b-4f4b-c2b7-06e384c5f474"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["0.8934000384837406\n"]}]},{"cell_type":"markdown","source":["교차 검증에서 얻은 점수와 매우 비슷한 결과를 얻었다.   \n","OOB 점수를 사용하면 교차 검증을 대신할 수 있어서 결과적으로 훈련 세트에 더 많은 샘플을 사용할 수 있다."],"metadata":{"id":"1HPq7zDA-DMS"}}]}